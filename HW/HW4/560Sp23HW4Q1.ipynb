{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwKpLUyP0cC3ve6VjRhwVf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yexf308/ATLAS/blob/main/HW/HW4/560Sp23HW4Q1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ziByFDYX08f"
      },
      "outputs": [],
      "source": [
        "%pylab inline \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import init\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "import torchvision.datasets as dset\n",
        "\n",
        "\n",
        "# for plotting\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['font.size'] = 16\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1: Autoencoders (35pt)\n",
        "In this homework, we will train two simple autoencoders to perform\n",
        "dimensionality reduction on MNIST. Autoencoders are a\n",
        "long-studied neural network architecture comprised of an encoder component to\n",
        "summarize the latent features of input data, and a decoder component to try and\n",
        "reconstruct the original data from the latent features.\n",
        "\n",
        "- **Initialization**: We recommend using `nn.Linear` for your linear layers. You will not need to initialize the weights yourself; the default He/Kaiming uniform initialization in PyTorch will be sufficient. We also recommend using the `nn.Sequential` module to organize your\n",
        "network class and simplify the process of writing the forward pass.\n",
        "\n",
        "- **Training**: Use `optim.Adam` for this question. Experiment with different learning rates. Use mean\n",
        "squared error (`nn.MSELoss()` or `F.mse\\_loss()`) for the loss function and ReLU for the non-linearity in b.\n",
        "\n"
      ],
      "metadata": {
        "id": "ixYGQALjQqt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load MNIST Dataset for Q1\n"
      ],
      "metadata": {
        "id": "CxbgccNqR-E0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "\n",
        "fig, axs = plt.subplots(3, 3,figsize=(5,5))\n",
        "axs = axs.ravel()\n",
        "\n",
        "for i in range(9):\n",
        "    axs[i].imshow(train_X[i], cmap=pyplot.get_cmap('gray'))"
      ],
      "metadata": {
        "id": "Yi9IJk84SMY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## Q1.1: Single linear layer (15pt)\n",
        "\n",
        "Use a network with a single linear layer. Let $W_{\\rm e} \\in \\mathbb{R}^{h \\times d}$ and $W_{\\rm d} \\in \\mathbb{R}^{d\\times h}$. Given some $x \\in \\mathbb{R}^d$, the forward pass is formulated as\n",
        "\\begin{align}\n",
        "      \\mathcal{F}_{1}(x) = W_{\\rm d} W_{\\rm e} x\\ .\n",
        "\\end{align}\n",
        "Run experiments for $h \\in \\{ 32, 64, 128 \\}$. For each of the different $h$ values, report your final error and visualize a set of $10$ reconstructed digits, side-by-side with the original image. \n",
        "\n",
        "**Note:** We omit the bias term in the formulation for notational convenience since `nn.Linear` learns bias parameters alongside weight parameters by default.\n",
        "    "
      ],
      "metadata": {
        "id": "Nih-scYkSTfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Q1.1 your code starts here"
      ],
      "metadata": {
        "id": "OZs0RIbuSZlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "H1aRjHDZStGM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "## Q1.2: Sigmoid layer (15pt)\n",
        "Use a single-layer network with non-linearity. Let $W_{\\rm e} \\in \\mathbb{R}^{h \\times d}$, $W_{\\rm d} \\in \\mathbb{R}^{d\\times h}$, and sigmoid activation $\\sigma\\colon \\mathbb{R} \\to \\mathbb{R}$. Given some $x \\in \\mathbb{R}^d$, the forward pass is formulated as \n",
        "\\begin{align}\n",
        "      \\mathcal{F}_{2}(x) = \\sigma\\left(W_{\\rm d} \\sigma\\left(W_{\\rm e} x\\right)\\right)\\ .\n",
        "\\end{align}\n",
        "Report the same findings as asked for in Q2.1 (for $h \\in \\{ 32, 64, 128 \\}$).\n",
        "\n"
      ],
      "metadata": {
        "id": "gyC3g1HsSwlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Q1.2 your code starts here"
      ],
      "metadata": {
        "id": "OCZzpwYXS8od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "Y9Z9bog5S-CS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Q1.3: Testing (5pt)\n",
        "Now, evaluate $\\mathcal{F}_1(x)$ and $\\mathcal{F}_2(x)$ (use $h = 128$ here) on the test set and report the results. In a few sentences, compare the quality of the reconstructions from these two autoencoders. \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "84qmtC-eTBQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Q1.3 your code starts here"
      ],
      "metadata": {
        "id": "ScJ7X2RmTJ9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Solution:"
      ],
      "metadata": {
        "id": "_9auZXv_TK-8"
      }
    }
  ]
}